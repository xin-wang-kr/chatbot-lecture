{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = \"\"\"Machine learning is a branch of artificial intelligence and computer science. \n",
    "Machine learning focuses on the use of data and algorithms to imitate the way that humans learn.\"\"\"\n",
    "\n",
    "# Download the punkt tokenizer\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = nltk.sent_tokenize(text_data)\n",
    "\n",
    "# Convert sentences to words\n",
    "sentences = [gensim.utils.simple_preprocess(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the text corpus, we can train the word2vec model using gensim. We can set different parameters for the word2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the word2vec model\n",
    "w2v = gensim.models.Word2Vec(\n",
    "    sentences=sentences,  # input data\n",
    "    vector_size=128,  # size of the vectors\n",
    "    window=5,  # window size\n",
    "    min_count=1,  # minimum count of words\n",
    "    epochs=3,  # number of iterations\n",
    "    hs=0,  # Turn off hierarchical softmax and use negative sampling\n",
    "    sg=1,  # Use skip-gram instead of CBOW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(w2v.wv.key_to_index)\n",
    "emb = w2v.wv[vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training process, we will get a high-dimensional vector space for text corpus. We can project this vector space into 2D or 3D to further observe the embedding relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce dimensionality\n",
    "reducer = umap.UMAP(n_components=3, random_state=42, n_neighbors=5, metric=\"cosine\")\n",
    "xyz = reducer.fit_transform(emb)\n",
    "\n",
    "# Create a 3D scatter plot with Seaborn\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "x=xyz[:, 0]\n",
    "y=xyz[:, 1]\n",
    "z=xyz[:, 2]\n",
    "ax.scatter(x, y, z, c=z, cmap='viridis', marker='o')\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "for i, c in enumerate(vocab):\n",
    "    ax.text(xyz[i,0],xyz[i,1],xyz[i,2],  '%s' % c, size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec Question and Answer Chatbot Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will create a Q-A chatbot only based on question search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 1: data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D66ZOAoNJouv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleTitle</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>DifficultyFromQuestioner</th>\n",
       "      <th>DifficultyFromAnswerer</th>\n",
       "      <th>ArticleFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alessandro_Volta</td>\n",
       "      <td>Was Alessandro Volta a professor of chemistry?</td>\n",
       "      <td>Alessandro Volta was not a professor of chemis...</td>\n",
       "      <td>easy</td>\n",
       "      <td>easy</td>\n",
       "      <td>data/set4/a10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alessandro_Volta</td>\n",
       "      <td>Did Alessandro Volta invent the remotely opera...</td>\n",
       "      <td>Alessandro Volta did invent the remotely opera...</td>\n",
       "      <td>easy</td>\n",
       "      <td>easy</td>\n",
       "      <td>data/set4/a10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alessandro_Volta</td>\n",
       "      <td>Was Alessandro Volta taught in public schools?</td>\n",
       "      <td>Volta was taught in public schools.</td>\n",
       "      <td>easy</td>\n",
       "      <td>easy</td>\n",
       "      <td>data/set4/a10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alessandro_Volta</td>\n",
       "      <td>Who did Alessandro Volta marry?</td>\n",
       "      <td>Alessandro Volta married Teresa Peregrini.</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>data/set4/a10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alessandro_Volta</td>\n",
       "      <td>What did Alessandro Volta invent in 1800?</td>\n",
       "      <td>In 1800, Alessandro Volta invented the voltaic...</td>\n",
       "      <td>medium</td>\n",
       "      <td>easy</td>\n",
       "      <td>data/set4/a10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ArticleTitle                                           Question  \\\n",
       "0  Alessandro_Volta     Was Alessandro Volta a professor of chemistry?   \n",
       "1  Alessandro_Volta  Did Alessandro Volta invent the remotely opera...   \n",
       "2  Alessandro_Volta     Was Alessandro Volta taught in public schools?   \n",
       "3  Alessandro_Volta                    Who did Alessandro Volta marry?   \n",
       "4  Alessandro_Volta          What did Alessandro Volta invent in 1800?   \n",
       "\n",
       "                                              Answer DifficultyFromQuestioner  \\\n",
       "0  Alessandro Volta was not a professor of chemis...                     easy   \n",
       "1  Alessandro Volta did invent the remotely opera...                     easy   \n",
       "2                Volta was taught in public schools.                     easy   \n",
       "3         Alessandro Volta married Teresa Peregrini.                   medium   \n",
       "4  In 1800, Alessandro Volta invented the voltaic...                   medium   \n",
       "\n",
       "  DifficultyFromAnswerer    ArticleFile  \n",
       "0                   easy  data/set4/a10  \n",
       "1                   easy  data/set4/a10  \n",
       "2                   easy  data/set4/a10  \n",
       "3                 medium  data/set4/a10  \n",
       "4                   easy  data/set4/a10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/workspaces/word2vec-chatbot-lecture/data/Question_Answer_Dataset_v1.2_S10.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqUJKWBcVH1Q",
    "outputId": "d71f4d05-c6b2-46ea-ec91-1e6f6cbcb491"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "DfjBSEcyezOH",
    "outputId": "7f539e50-5cb8-4b9b-c130-f4a017f52de0"
   },
   "outputs": [],
   "source": [
    "df[\"Answer\"][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "15X6qaDbdBL1",
    "outputId": "dad984b1-2351-4141-95c6-59c1bbe0814f"
   },
   "outputs": [],
   "source": [
    "df[\"Answer\"][14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data, there are both text and numbers. We need to generate a set of corpus including both of them. Based on this, we cannot use gensim.utils.simple_preprocess to prepare corpus. Here, we will use regular expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omm6nuVyfZ2N",
    "outputId": "66e3f0d1-d669-4777-d360-31b5986b7e6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original string is : Gfg, is best : for ! Geeks ;? 123 a 9...\n",
      "The string after punctuation filter :  ['Gfg', 'is', 'best', 'for', 'Geeks', '123', 'a', '9']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# initializing string\n",
    "test_str = \"Gfg, is best : for ! Geeks ;? 123 a 9...\"\n",
    "\n",
    "# printing original string\n",
    "print(\"The original string is : \" + test_str)\n",
    "\n",
    "# Removing punctuations in string\n",
    "res = re.sub(r'[^\\w\\s]', '', test_str)\n",
    "# Replace all sequences of two or more spaces with a single space.\n",
    "res = re.sub(' +', ' ', res)\n",
    "\n",
    "# printing result\n",
    "print(\"The string after punctuation filter : \", res.strip().split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 2: word2vec model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IQrG9X-GVvsT"
   },
   "outputs": [],
   "source": [
    "# train word2vec model with all questions\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = df[\"Question\"].to_list()\n",
    "\n",
    "def token(text):\n",
    "  # Removing punctuations in string\n",
    "  res = re.sub(r'[^\\w\\s]', '', text)\n",
    "  # Replace all sequences of two or more spaces with a single space.\n",
    "  res = re.sub(' +', ' ', res)\n",
    "  # lower case\n",
    "  res = res.lower()\n",
    "  return res.strip().split(\" \")\n",
    "\n",
    "# Convert sentences to words\n",
    "sentences = [token(text) for text in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-rh11_2YWH_Z"
   },
   "outputs": [],
   "source": [
    "w2v = gensim.models.Word2Vec(\n",
    "    sentences=sentences,  # input data\n",
    "    vector_size=128,  # size of the vectors\n",
    "    window=5,  # window size\n",
    "    min_count=1,  # minimum count of words\n",
    "    epochs=3,  # number of iterations\n",
    "    hs=0,  # Turn off hierarchical softmax and use negative sampling\n",
    "    sg=1,  # Use skip-gram instead of CBOW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyFpA7ZbYBjP"
   },
   "outputs": [],
   "source": [
    "w2v.save(\"/workspaces/word2vec-chatbot-lecture/data/w2v.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 3: generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CFdwEcdEWNbD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculate sentence vector for each sentence\n",
    "def sentence_vec(sent):\n",
    "    # Filter out terms that are not in the vocabulary from the question sentence\n",
    "    tm_voc = [tm for tm in sent if tm in w2v.wv]\n",
    "    # Get the embedding of the characters\n",
    "    emb = np.vstack([w2v.wv[tm] for tm in tm_voc])\n",
    "    # Calculate the vectors of each included word to get the vector of the question\n",
    "    ave_vec = np.mean(emb, axis=0)\n",
    "    return ave_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7Cy2ll2cWOb1"
   },
   "outputs": [],
   "source": [
    "ques_vec = [sentence_vec(sent) for sent in sentences[:df.shape[0]]]\n",
    "ques_vec = np.array(ques_vec)\n",
    "#ans_vec = [sentence_vec(sent) for sent in sentences[df.shape[0]:]]\n",
    "\n",
    "np.savez(\"/workspaces/word2vec-chatbot-lecture/data/vector.npz\", x=ques_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE:__ You can also save answer vectors through giving another array keyword. For example: np.savez(\"/content/sample_data/vector.npz\", x=ques_vec, y=ans_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 4: vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector search is a machine learning technique that uses numeric representations of content to find similar items in a dataset. Cosine similarity measurement is a common way to conduct vector search.\n",
    "\n",
    "[Faiss](https://github.com/facebookresearch/faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. Faiss is written in C++ with complete wrappers for Python/numpy. Some of the most useful algorithms are implemented on the GPU. It is developed primarily at Meta's Fundamental AI Research group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MYfWon89eThO"
   },
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAISS similarity search example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TEiqSfmeZbr",
    "outputId": "4c29fede-d942-46a5-d384-c9f9694c5fd7"
   },
   "outputs": [],
   "source": [
    "dataSetI = [.1, .2, .3]\n",
    "dataSetII = [.4, .5, .6]\n",
    "#dataSetII = [.1, .2, .3]\n",
    "dataSetIII = [.4, .5, .7]\n",
    "\n",
    "x = np.array([dataSetI]).astype(np.float32)\n",
    "q = np.array([dataSetII]).astype(np.float32)\n",
    "index = faiss.index_factory(3, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "#index.ntotal\n",
    "faiss.normalize_L2(x)\n",
    "index.add(x)\n",
    "y = np.array([dataSetIII]).astype(np.float32)\n",
    "faiss.normalize_L2(y)\n",
    "index.add(y)\n",
    "faiss.normalize_L2(q)\n",
    "distance, index = index.search(q, k=index.ntotal)\n",
    "print('Distance by FAISS:{}'.format(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGi8sK4lezoi",
    "outputId": "ff9d0afe-af02-447b-8a8b-93794607c271"
   },
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6Oc0A8Rgovt",
    "outputId": "edeb2ef6-5dac-473d-a2fb-18f5bb498db9"
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "result = 1 - spatial.distance.cosine(dataSetI, dataSetII)\n",
    "print('Distance by FAISS:{}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to generate query sentence vector and find matched answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "upgqqXODJvoP"
   },
   "outputs": [],
   "source": [
    "def trained_sentence_vec(sent):\n",
    "    # Filter out terms that are not in the vocabulary from the question sentence\n",
    "    qu_voc = [tm for tm in sent if tm in w2v.wv]\n",
    "    # Get the embedding of the characters\n",
    "    emb = np.vstack([w2v.wv[tm] for tm in qu_voc])\n",
    "    # Calculate the vectors of each included word to get the vector of the question\n",
    "    ave_vec = np.mean(emb, axis=0)\n",
    "    return ave_vec\n",
    "\n",
    "def find_answer(qr_sentence, ques_vec):\n",
    "    # use one query sentence to retrieve answer\n",
    "    qr_sentence = gensim.utils.simple_preprocess(qr_sentence)\n",
    "    qr_sent_vec = trained_sentence_vec(qr_sentence)\n",
    "\n",
    "    # perform vector search through similarity comparison\n",
    "    n_dim = ques_vec.shape[1]\n",
    "    x = np.vstack(ques_vec).astype(np.float32)\n",
    "    q = qr_sent_vec.reshape(1, -1)\n",
    "    index = faiss.index_factory(n_dim, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "    faiss.normalize_L2(x)\n",
    "    index.add(x)\n",
    "    faiss.normalize_L2(q)\n",
    "    similarity, idx = index.search(q, k=index.ntotal)\n",
    "    ans_idx = idx[0][0]\n",
    "    return ans_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  What did Alessandro Volta invent in 1800?\n",
      "Question:  What did Alessandro Volta invent in 1800?\n",
      "Answer:  In 1800, Alessandro Volta invented the voltaic pile.\n"
     ]
    }
   ],
   "source": [
    "qr_sentence = \"What did Alessandro Volta invent in 1800?\"\n",
    "ans_idx = find_answer(qr_sentence, ques_vec)\n",
    "print(\"Query: \", qr_sentence)\n",
    "print(\"Question: \", df[\"Question\"][ans_idx])\n",
    "print(\"Answer: \", df[\"Answer\"][ans_idx])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
